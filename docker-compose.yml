version: '3.8'

services:
  gemma-service:
    # 로컬 Dockerfile에서 빌드
    build:
      context: .
      dockerfile: Dockerfile
    image: gemma-3-service:local
    container_name: gemma-3-server
    restart: always
    runtime: nvidia
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - HF_HOME=/root/.cache/huggingface
      # 드라이버 버전 우회
      # - NVIDIA_DISABLE_REQUIRE=1
    volumes:
      # 호스트의 캐시 경로를 꼭 확인하고 맞춰주세요
      - /mnt/data2/hf_cache:/root/.cache/huggingface
    ports:
      - "8000:8000"
    ipc: host

    # RTX 3090 24GB: 12B 모델은 양자화 필수
    # BitsAndBytes 4bit 양자화로 ~6GB로 압축 → 동시처리 여유 확보
    command: >
      google/gemma-3-12b-it
      --dtype bfloat16
      --quantization bitsandbytes
      --load-format bitsandbytes
      --tensor-parallel-size 1
      --gpu-memory-utilization 0.90
      --max-model-len 4096
      --trust-remote-code